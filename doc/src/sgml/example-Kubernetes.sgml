<sect1 id="example-Kubernetes">
 <title><productname>Pgpool-II</productname> on Kubernetes</title>
 <para>
  This section explains how to run <productname>Pgpool-II</productname> to achieve
  read query load balancing and connection pooling on Kubernetes.
 </para>
 <sect2 id="example-Kubernetes-intro">
  <title>Introduction</title>
  <para>
   Because <productname>PostgreSQL</productname> is a stateful application and managing
   <productname>PostgreSQL</productname> has very specific requirements (e.g. backup,
   recovery, automatic failover, etc), the built-in functionality of <productname>Kubernetes</productname>
   can't handle these tasks. Therefore, an Operator that extends the functionality of the Kubernetes to create
   and manage PostgreSQL is required.
  </para>
  <para>
   There are several PostgreSQL operators, such as
   <ulink url="https://github.com/CrunchyData/postgres-operator">Crunchy PostgreSQL Operator</ulink>,
   <ulink url="https://github.com/zalando/postgres-operator">Zalando PostgreSQL Operator</ulink> and
   <ulink url="https://github.com/kubedb/operator">KubeDB</ulink>.
   However, these operators don't provide query load balancing functionality.
  </para>
  <para>
   This section explains how to combine PostgreSQL Operator with Pgpool-II to deploy a PostgreSQL cluster
   with query load balancing and connection pooling capability on Kubernetes. Pgpool-II can be combined with
   any of the PostgreSQL operators mentioned above.
  </para>
 </sect2>

 <sect2 id="example-Kubernetes-architecture">
  <title>Architecture</title>
  <para>
   <figure>
    <title>Architecture</title>
    <mediaobject>
     <imageobject>
      <imagedata fileref="pgpool_on_k8s.gif">
     </imageobject>
    </mediaobject>
   </figure>
  </para>
 </sect2>

 <sect2 id="example-Kubernetes-pre-setup">
  <title>Prerequisites</title>
  <para>
   Before you start the configuration process, please check the following prerequisites.
  <itemizedlist>
   <listitem>
    <para>
     Make sure you have a <productname>Kubernetes</productname> cluster, and <command>kubectl</command> is installed.
    </para>
   </listitem>
   <listitem>
    <para>
     PostgreSQL Operator and a PostgreSQL cluster are installed.
    </para>
   </listitem>
  </itemizedlist>
  </para>
 </sect2>

 <sect2 id="example-Kubernetes-deploy-pgpool">
  <title>Deploy Pgpool-II</title>
  <para>
   Deploy Pgpool-II pod that contains a Pgpool-II container and a
   <ulink url="https://github.com/pgpool/pgpool2_exporter">Pgpool-II Exporter</ulink> container.
  </para>
  <programlisting>
apiVersion: apps/v1
kind: Deployment
metadata:
  name: pgpool
spec:
  replicas: 1
  selector:
    matchLabels:
      app: pgpool
  template:
    metadata:
      labels:
        app: pgpool
    spec:
      containers:
      - name: pgpool
        image: pgpool/pgpool:4.2
    ...
      - name: pgpool-stats
        image: pgpool/pgpool2_exporter:1.0
    ...
  </programlisting>
  <para>
   <productname>Pgpool-II</productname>'s health check, automatic failover, Watchdog and online recovery features
   aren't required on <productname>Kubernetes</productname>. You need to only enable load balancing and connection
   pooling.
  </para>
  <para>
   The Pgpool-II pod should work with the minimal configuration below:
  </para>
  <programlisting>
backend_hostname0='primary service name'
backend_hostname1='replica service name'
backend_port0='5432'
backend_port1='5432'
backend_flag0='ALWAYS_PRIMARY|DISALLOW_TO_FAILOVER'
backend_flag1='DISALLOW_TO_FAILOVER'

sr_check_period = 10
sr_check_user='PostgreSQL user name'

load_balance_mode = on
connection_cache = on
listen_addresses = '*'
  </programlisting>
  <para>
   There are two ways you can configure Pgpool-II.
   <orderedlist>
    <listitem>
     <para>
      Using environment variables
     </para>
    </listitem>
    <listitem>
     <para>
      Using a <ulink url="https://kubernetes.io/docs/concepts/configuration/configmap/">ConfigMap</ulink>
     </para>
    </listitem>
   </orderedlist>
  </para>
  <para>
   You may need to configure client authentication and more parameters in a production environment.
   In a production environment, we recommend using a ConfigMap to configure Pgpool-II's
   config files, i.e. pgpool.conf, pcp.conf, pool_passwd and pool_hba.conf.
  </para>
  <para>
   The following sections explain how to configure and deploy Pgpool-II pod using environment
   variables and ConfigMap respectively. You can download the various manifest files used for
   deploying Pgpool-II from <ulink url="https://github.com/pgpool/pgpool2_on_k8s">here</ulink>.
  </para>

  <sect3 id="example-Kubernetes-configure-pgpool-env">
   <title>Configure Pgpool-II using environment variables</title>
   <para>
    Kubernetes environment variables can be passed to a container in a pod.
    You can define environment variables in the deployment manifest to configure Pgpool-II's parameters.
    <filename>pgpool_deploy.yaml</filename> is an example of a Deployment manifest.
    You can download <filename>pgpool_deploy.yaml</filename> and specify environment variables in this manifest file.
   </para>
   <programlisting>
$ curl -LO https://raw.githubusercontent.com/pgpool/pgpool2_on_k8s/master/pgpool_deploy.yaml
   </programlisting>
   <para>
    Environment variables starting with <literal>PGPOOL_PARAMS_</literal> can be converted to Pgpool-II's configuration
    parameters and these values can override the default configurations.
   </para>
   <itemizedlist>
    <listitem>
     <para>
      The Pgpool-II container Docker images is build with streaming replication mode.
      By default, load balancing, connection pooling and streaming replication check is enabled.
     </para>
    </listitem>
    <listitem>
     <para>
      Specify <emphasis>only two backend nodes</emphasis>.
      Specify the Primary Service name to <xref linkend="GUC-BACKEND-HOSTNAME">0.
      Specify the Replica Service name to <xref linkend="GUC-BACKEND-HOSTNAME">1.
      Because failover is managed by <productname>Kubernetes</productname>,
      specify <literal>DISALLOW_TO_FAILOVER</literal> flag to <xref linkend="GUC-BACKEND-FLAG">
      for both of the two nodes and <literal>ALWAYS_PRIMARY</literal> flag to <xref linkend="GUC-BACKEND-FLAG">0.
      Configure appropriate <xref linkend="GUC-BACKEND-WEIGHT"> as usual.
      You don't need to specify <xref linkend="GUC-BACKEND-DATA-DIRECTORY">.
     </para>
     <para>
      For example, the following environment variables defined in manifest,
     </para>
     <programlisting>
env:
- name: PGPOOL_PARAMS_BACKEND_HOSTNAME0
  value: "hippo"
- name: PGPOOL_PARAMS_BACKEND_HOSTNAME1
  value: "hippo-replica"
- name: PGPOOL_PARAMS_BACKEND_FLAG0
  value: "ALWAYS_PRIMARY|DISALLOW_TO_FAILOVER"
- name: PGPOOL_PARAMS_BACKEND_FLAG1
  value: "DISALLOW_TO_FAILOVER"
     </programlisting>
     <para>
      will be convert to the following configuration parameters in pgpool.conf.
     </para>
     <programlisting>
backend_hostname0='hippo'
backend_hostname1='hippo-replica'
backend_flag0='ALWAYS_PRIMARY|DISALLOW_TO_FAILOVER'
backend_flag1='DISALLOW_TO_FAILOVER'
     </programlisting>
    </listitem>
    <listitem>
     <para>
      Specify a PostgreSQL user name and password to perform streaming replication check.
      For the security reasons, we recommend that you specify a encrypted password.
     </para>
     <programlisting>
- name: PGPOOL_PARAMS_SR_CHECK_USER
  value: "PostgreSQL user name"
- name: PGPOOL_PARAMS_SR_CHECK_PASSWORD
  value: "encrypted PostgreSQL user's password"
     </programlisting>
     <para>
      Alternatively, you can create a secret and use this secret as environment variables.
     </para>
    </listitem>
    <listitem>
     <para>
      Since health check is performed by <productname>Kubernetes</productname>, Pgpool-II's health check should be disabled.
      Because the default value is off, we don't need to set this parameter.
     </para>
    </listitem>

    <listitem>
     <para>
      By default, the following environment variables will be set when Pgpool-II container is started.
     </para>
     <programlisting>
export PGPOOL_PARAMS_LISTEN_ADDRESSES=*
export PGPOOL_PARAMS_SR_CHECK_USER=${POSTGRES_USER:-"postgres"}
export PGPOOL_PARAMS_SOCKET_DIR=/var/run/postgresql
export PGPOOL_PARAMS_PCP_SOCKET_DIR=/var/run/postgresql
     </programlisting>
    </listitem>
   </itemizedlist>
  </sect3>
  <sect3 id="example-Kubernetes-configure-pgpool-configmap">
   <title>Configure Pgpool-II using ConfigMap</title>
   <para>
    Alternatively, you can use a Kubernetes <literal>ConfigMap</literal> to store entire configuration files,
    i.e. pgpool.conf, pcp.conf, pool_passwd and pool_hba.conf.
    The <literal>ConfigMap</literal> can be mounted to Pgpool-II's container as a volume.
   </para>
   <para>
    You can download the example manifest files that define the <literal>ConfigMap</literal> and <literal>Deployment</literal>
    from <ulink url="https://github.com/pgpool/pgpool2_on_k8s">repository</ulink>.
   </para>
   <programlisting>
curl -LO https://raw.githubusercontent.com/pgpool/pgpool2_on_k8s/master/pgpool_configmap.yaml
curl -LO https://raw.githubusercontent.com/pgpool/pgpool2_on_k8s/master/pgpool_deploy_with_mount_configmap.yaml
   </programlisting>
   <para>
    The manifest that defines the <literal>ConfigMap</literal> is in the following format. You can update it based
    on your configuration preferences.
   </para>
   <programlisting>
apiVersion: v1
kind: ConfigMap
metadata:
  name: pgpool-config
  labels:
    app: pgpool-config
data:
  pgpool.conf: |-
    listen_addresses = '*'
    port = 9999
    socket_dir = '/var/run/postgresql'
    pcp_listen_addresses = '*'
    pcp_port = 9898
    pcp_socket_dir = '/var/run/postgresql'
    backend_hostname0 = 'hippo'
    backend_port0 = 5432
    backend_weight0 = 1
    backend_flag0 = 'ALWAYS_PRIMARY|DISALLOW_TO_FAILOVER'
    backend_hostname1 = 'hippo-replica'
    backend_port1 = 5432
    backend_weight1 = 1
    backend_flag1 = 'DISALLOW_TO_FAILOVER'
    sr_check_user = 'postgres'
    sr_check_period = 10
    enable_pool_hba = on
    master_slave_mode = on
    num_init_children = 32
    max_pool = 4
    child_life_time = 300
    child_max_connections = 0
    connection_life_time = 0
    client_idle_limit = 0
    connection_cache = on
    load_balance_mode = on
  pcp.conf: |-
    postgres:e8a48653851e28c69d0506508fb27fc5
  pool_passwd: |-
    postgres:md53175bce1d3201d16594cebf9d7eb3f9d
  pool_hba.conf: |-
    local   all         all                               trust
    host    all         all         127.0.0.1/32          trust
    host    all         all         ::1/128               trust
    host    all         all         0.0.0.0/0             md5
   </programlisting>
   <para>
    First, you need to create the <literal>ConfigMap</literal> before referencing it to <productname>Pgpool-II</productname> pod.
   </para>
   <programlisting>
kubectl apply -f pgpool_configmap.yaml
   </programlisting>
   <para>
    Once you have created the <literal>ConfigMap</literal>, you can deploy <productname>Pgpool-II</productname> pod and
    mount the <literal>ConfigMap</literal> to Pgpool-II pod as a volume.
   </para>
   <programlisting>
apiVersion: apps/v1
kind: Deployment
metadata:
  name: pgpool
  ...
        volumeMounts:
        - name: pgpool-config
          mountPath: /usr/local/pgpool-II/etc
      ...
      volumes:
      - name: pgpool-config
        configMap:
          name: pgpool-config
   </programlisting>
   <para>
    <filename>pgpool_deploy_with_mount_configmap.yaml</filename> is an example of a Deployment manifest that mounts the
    created <literal>ConfigMap</literal> to the <productname>Pgpool-II</productname> pod.
   </para>
   <programlisting>
kubectl apply -f pgpool_deploy_with_mount_configmap.yaml
   </programlisting>
  <para>
   After deploying Pgpool-II, you can see the Pgpool-II pod and services using <command>kubectl get pod</command>
   and <command>kubectl get svc</command> command.
  </para>
  </sect3>
 </sect2>
</sect1>
